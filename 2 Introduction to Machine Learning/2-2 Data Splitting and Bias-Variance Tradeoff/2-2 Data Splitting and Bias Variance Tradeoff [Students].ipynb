{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science] \n",
    "\n",
    "## 2-2 Data Splitting and Bias/Variance Tradeoff - Student Version\n",
    "\n",
    "In this lab, we will introduce the fundamentals of machine learning. We will introduced supervised methods, bias/variance tradeoff, and data splitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by introducing the concept of supervised learning. We're going to work with [Census Income dataset](https://archive.ics.uci.edu/ml/datasets/Census+Income) on the UCI Machine Learning Repository. In supervised machine learning, we start with a structured dataset where each observation is a row and each variable is a column. The goal is to use a number of features (previously you might have called these \"covariates,\" \"independent variables,\" or \"regressors\") to train a model that predicts a target (previously you might have called these \"outcome variable\" or \"dependent variable\"). In this case, we will use information like age, education, and marital status to predict each person's income-bracket.\n",
    "\n",
    "First let's load the data. The data is stored in a \".data\" format so we'll use the pandas \"read_table\" method. Be sure to investigate the data carefully. What happens if we don't include a col_names argument when reading in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries \n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of column names for the data so we can label the columns\n",
    "col_names = ['age', \n",
    "             'workclass', \n",
    "             'fnlwgt',\n",
    "             'education', \n",
    "             'education-num',\n",
    "             'marital-status', \n",
    "             'occupation', \n",
    "             'relationship', \n",
    "             'race', \n",
    "             'sex', \n",
    "             'capital-gain',\n",
    "             'capital-loss', \n",
    "             'hours-per-week',\n",
    "             'native-country', \n",
    "             'income-bracket']\n",
    "\n",
    "# read table from the data folder \n",
    "census = pd.read_table(\"../../data/adult.data\", # refers to the subfolder called \"data\" to load the data\n",
    "                       sep = ',',               # comma delimited file (stored as .data file not .csv)\n",
    "                       names = col_names)       # applies \"col_names\" list to label columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first 5 rows\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use these features to predict an individual's predict income-bracket. We need to think about a few questions.\n",
    "\n",
    "1. What features should we include?\n",
    "2. What is the best model?\n",
    "3. How do we evaluate the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's think about the features. Check the different data types in our dataset. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view data types\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we pass these features into a model, we need to convert the categorical features to numerical information. So basically, we want numbers to stand in for the categories. Since our target is also categorical, we will need to transform that column as well. \n",
    "\n",
    "Starting with the outcome, \"income-bracket,\" use sklearn's [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) to convert the **income-bracket** column to a binary outcome (0 for \"<=50k\" and 1 for \">50k\"). Instead of simply renaming the column, we'll call it something slighty different but informative. This way we maintain the old column in our dataset, which allows us check the new coding against the old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# create an instance of LabelBinarizer as lb so we can call it as method on the data\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# transform the variable\n",
    "census['income-bracket-binary'] = lb.fit_transform(census[\"income-bracket\"]) \n",
    "\n",
    "# preview data\n",
    "census.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the features we will use for prediction. There are a couple of different ways we could convert our categorical features to numerical ones. One simple way to do this is to convert them into dummy variables. Use the pandas [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) method to convert the categorical variables into dummy variables. *Be sure to remove the target variable (both the original and binarized versions) with* `.drop()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new object of features (X) by dropping our label (outcome) from the dataframe with .drop() method.\n",
    "X = census. ... # which axis refers to columns?\n",
    "\n",
    "# use the pandas \"get_dummies method\" to get create dummies for our categorical data\n",
    "X = pd.get_dummies(...)\n",
    "\n",
    "# preview these changes in the data\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all of our categorical variables have been converted. Instead of strings, we now either have a 0 or a 1 in their place, and new columns representing each category. \n",
    "\n",
    "**Question:** Take a look at the shape and structure of this new dataframe compared to the original. What can you say about these two dataframes? Is there new information, or is it presented differently? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions of Dummy Dataframe are\", X.shape)\n",
    "print(\"Dimensions of the Original Dataframe are\", census.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curse of Dimensionality and Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data preprocessing step reveals two important concepts in machine learning: [**the curse of dimensionality** and **sparsity**](https://www.kaggle.com/residentmario/curse-of-dimensionality). \n",
    "\n",
    "- A **sparse matrix** is one filled mainly with 0's, as we see above. In geometric terms, this means that most combinations of features are totally empty. \n",
    "\n",
    "- The **curse of dimensionality** refers to the idea that as the number of features grow, the number of observations needed to properly model predictions grows as well. The problem is that that number of observations required grows much faster than the number of features. So, there's a fundamental trade off between increasing the number features to improve model performance, but reducing it to avoid the instability and overfitting that will occur with too few observations. This another important tradeoff at the heart of supervised machine learning. \n",
    "\n",
    "In the coming weeks, we will learn more about how to conceptualize and make these tradeoffs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another key aspect of machine learning is splitting our data. In your previous statistics classes, you likely fit regression models on an entire dataset. The problem with fitting a model this way is that models will tend to perform better on the data that they are trained on, but then perform less well on out of sample data. In some ways, the framework we will use in machine learning has grown out of this critque, but also is a result of a stronger focus on prediction. \n",
    "\n",
    "Remember, the error in a machine learning model comes from two sources:\n",
    "\n",
    "**Bias**: Error arising from the difference between the predicted output and the actual output. High bias models tend to be too simple and **underfit** the dataset.\n",
    "\n",
    "**Variance**: Error arising from modeling the noise in the output. High variance models tend to be too complex and **overfit** the dataset.\n",
    "\n",
    "The [**bias-variance tradeoff**](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) is a fundamental concept in machine learning. The less bias in a model, the higher the variance and vice versa. [Underfitting or overfitting](https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html) a model makes generalizing to new data difficult. Trading off between these two sources of error is an essential part of machine learning. \n",
    "\n",
    "Over the next few weeks, we will explore how to deal with bias-variance tradeoff in the modeling process. Today, we'll look at how our choices in the data splitting step affect the bias-variance tradeoff as well.\n",
    "\n",
    "In the meantime, the following visualization is helpful in separating bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![bias_variance_tradeoff.png](../../images/bias_variance_tradeoff.png)\n",
    "\n",
    "Image taken from blog by [Angel and Kezhan Shi](https://towardsdatascience.com/what-bias-variance-bulls-eye-diagram-really-represent-ff6fb9670993#:~:text=Relationship%20to%20Overfitting%20and%20underfitting&text=Now%20if%20we%20go%20back,high%20variance%20and%20low%20bias)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, machine learning models will tend to overfit the data they are trained on. As a machine learning model becomes more complex, it learns many of the idiosyncrasies in a dataset, but this tendency will mean it generalizes poorly. To assess the extent a model is prone to this problem, and make corrections, we always split our data before training our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general procedure for this is the following:\n",
    "1. Randomly divide our data set into two smaller sets: one for training and one for testing\n",
    "2. Train the data on the training set, changing our model along the way to increase accuracy\n",
    "3. Test the data's predictions using in test set.\n",
    "\n",
    "Scikit-learn's [test_train_split function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) will help here. First, separate your data into two parts: a dataframe containing the features used to make our prediction, and an array of the true targets. We already made a dataframe with our features earlier when we created dummy variables, so now we need to make a target vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View dataset\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with just the outcome\n",
    "y = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, set a random seed to ensure that we all get the same results when we sample. Then, use train_test_split to create a training set that contains 80% of the original dataset and a test set with 20% of the original data. Then check the shapes of each of the new sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library for training-testing-splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(10)\n",
    "\n",
    "# split the data\n",
    "# train_test_split returns 4 values: X_train, X_test, y_train, y_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(...,               # specify features  \n",
    "                                                    ...,               # specify labels\n",
    "                                                    ...,               # set training proportional spilt\n",
    "                                                    ...)               # set testing proportional spilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape of each newly created dataframe\n",
    "print(\"Shape of X train is\", ...)\n",
    "print(\"Shape of y_train is\", ...)\n",
    "print(\"Shape of X_test is\", ...)\n",
    "print(\"Shape of y_test is\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a check on the proportional splits, we can show an 80 and 20 percent spilt of the original datafame `X` match the sample size of the training and testing datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify proportional splits\n",
    "print(\"100% of original dataset\", X.shape[0])\n",
    "print(\"80% of full dataset\", X.shape[0]*.8)\n",
    "print(\"20% of full dataset\", X.shape[0]*.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we may want to adjust our models, it is generally a good idea to save the test set until the very end and only use it once. Instead of going back and forth between the training and test set, we should instead use a validation set. \n",
    "\n",
    "Try using the `train_test_split` method to further split your training data so that 75% remains in training and 25% is reserved for validation. Note that this will mean the **final split is 60% train, 20% validation, and 20% test.** Check the dimensions of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the trainting dataset again into two validation datasets\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(...,             # specify training x\n",
    "                                                            ...,             # specify training y\n",
    "                                                            ...,             # set training proportional spilt\n",
    "                                                            ...)             # set testing proportional split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use shape attribute to check out how many rows and columns you have in your train and test data\n",
    "print(\"Shape of X train is\", ...)\n",
    "print(\"Shape of X_validate is\", ...)\n",
    "print(\"Shape of X_test is\", ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a check on the proportional splits, we can show a 60 and 20 percent spilt of the original datafame `X` match the sample size of the training, testing, and validating datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify proportional splits\n",
    "print(\"100% of original dataset\", X.shape[0])\n",
    "print(\"60% of full dataset\", X.shape[0]*.6)\n",
    "print(\"20% of full dataset\", X.shape[0]*.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to fit a model. We'll use a logistic regression and find out how accurate our model is in the validation set. We'll explore fitting multiple models and adjusting them in coming weeks, but for now we'll start with one that you're familiar with. \n",
    "\n",
    "See the documentation for [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) to see how to train a model and predict on new data. Make sure you train the model on your train set, and predict on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# intitiate instance of logit model\n",
    "log_reg = ...\n",
    "\n",
    "# fit the model - learning the relationship between features (x_train) and labels (y_train)\n",
    "log_model = ...\n",
    "\n",
    "# pull out the predicted values and store as an object\n",
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize how we did. A common tool to see how a supervised machine algorithm performed in a classification setting is the [confusion matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). Each cell in the confusion matrix shows the relationship between the true observations on the y-axis and the predicted observations on the x-axis. Cells along the diagonal (moving from upper right to lower right) are instances where the predictions match the true labels.\n",
    "\n",
    "Call Scikit-Learn's `confusion_matrix` using the y_validate and y_pred variables. Have a look in the documentation at the `normalize` parameter as well, and how it influences the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cf_matrix = ...\n",
    "\n",
    "# turn cf_matrix into a dataframe for plotting purposes\n",
    "df_cm = pd.DataFrame(cf_matrix)\n",
    "\n",
    "\n",
    "# label dataframe \n",
    "df_cm = df_cm.rename(index   = {0: \"<=50k\", 1: \">50k\"}, # label rows\n",
    "                     columns = {0: \"<=50k\", 1: \">50k\"}) # label columns\n",
    "\n",
    "# plot figure\n",
    "plt.figure(figsize = (10,7))                     # set figure size\n",
    "sns.set(font_scale = 1.4)                        # set label size\n",
    "\n",
    "# specify heat map\n",
    "sns.heatmap(df_cm,                               # specify dataframe                          \n",
    "           annot=True,                           # display data values       \n",
    "           annot_kws={\"size\": 16},               # format data values\n",
    "           fmt='g')                              # format values as \"general\"      \n",
    "\n",
    "# labels \n",
    "plt.title(\"Confusion Matrix\")                    # label title\n",
    "plt.xlabel(\"Predicted Label\")                    # label x axis\n",
    "plt.ylabel(\"True Label\")                         # label y axis     \n",
    "plt.show()                                       # show label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Using the [iris](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) dataset, (see [this](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html) for more documentation) write a for loop that varies the training set size and visualize how performance changes as you increase the training size. What tends to happens? Use the census dataset that we've been working with so far, but it may take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# load iris data as an array\n",
    "iris = load_iris()\n",
    "\n",
    "# create X and y objects\n",
    "X_iris = iris.data[:, 0:2]        # just take the first two features\n",
    "y_iris = iris.target              # just take the targets ()\n",
    "\n",
    "# look at shape of array\n",
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the dataset size we want to loop through as a percent\n",
    "sizes = np.arange(.2, 1, .10)\n",
    "\n",
    "# create loop\n",
    "for size in sizes:\n",
    "    \n",
    "    # split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(..., \n",
    "                                                        train_size=size, # set training size\n",
    "                                                        random_state=10, # set a random seed\n",
    "                                                        shuffle=True,    # shuffle the data\n",
    "                                                        stratify=y_iris) # stratify by outcome\n",
    "        \n",
    "\n",
    "    # create instance of Logisitic regression \n",
    "    log_reg = ...\n",
    "    \n",
    "    # fit the model\n",
    "    log_model = ...\n",
    "    \n",
    "    # save prediction \n",
    "    y_pred = ...\n",
    "\n",
    "    # specify confusion matrix\n",
    "    cf_matrix = ...\n",
    "    \n",
    "    # convert matrix to dataframe\n",
    "    df_cm = ...\n",
    "\n",
    "    # rename rows and columns: can find the key to this data set using the target and target_names attributes\n",
    "    df_cm = df_cm.rename(index  ={0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"}, \n",
    "                         columns={0: \"Setosa\", 1: \"Versicolor\", 2: \"Virginica\"})\n",
    "\n",
    "    # plot figure\n",
    "    plt.figure(figsize = (10,7))                     # set figure size\n",
    "    sns.set(font_scale=1.4)                          # set label size\n",
    "\n",
    "    # specify heat map\n",
    "    sns.heatmap(df_cm,                               # specify dataframe                          \n",
    "               annot=True,                           # display data values       \n",
    "               annot_kws={\"size\": 16},               # format data values\n",
    "               fmt='g')                              # format values as \"general\"  \n",
    "\n",
    "    # labels \n",
    "    plt.title(\"Training Set Size \" + str(size))       # label title\n",
    "    plt.xlabel(\"Predicted Label\")                     # label x axis\n",
    "    plt.ylabel(\"True Label\")                          # label y axis     \n",
    "    plt.show()                                        # show label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, choosing the optimal train/validation/test split can be difficult. It is also prone to high variance problems as the machine learning algorithm's performance will be very dependent on the composition of the randomly sampled test split. This problem is exacerbated in small datasets especially. One way to address this problem is with [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#:~:text=Cross%2Dvalidation%2C%20sometimes%20called%20rotation,to%20an%20independent%20data%20set).\n",
    "\n",
    "The general procedure is:\n",
    "\n",
    "1. Randomly split the data into k-folds\n",
    "2. Build the model on k-1 folds, then test on the last fold\n",
    "3. Record prediction error\n",
    "4. Cycle until each fold has served as the test set\n",
    "5. The average of the errors is the cv-error\n",
    "\n",
    "Cross-validation has the advantage of allowing every data point to be in the test set once. By averaging the errors, the model is less sensitive to variation in the random samples, and is less prone to overfitting. Let's try with our logistic regression again, using the [cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# create features dataset\n",
    "X = census.drop(['income-bracket', 'income-bracket-binary'], \n",
    "                axis = 1)    # drops columns                   \n",
    "\n",
    "# get dummies\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# create target\n",
    "y = census['income-bracket-binary']\n",
    "\n",
    "# \n",
    "log_pred = ...\n",
    "\n",
    "# specify confusion matrix\n",
    "cf_matrix = confusion_matrix(y,                     # actual targets (ground truth)\n",
    "                             log_pred,              # estimated targets \n",
    "                             normalize = \"true\")    # normalize confusion matrix over rows and columns \n",
    "\n",
    "\n",
    "# turn cf_matrix into a dataframe for plotting purposes\n",
    "df_cm = pd.DataFrame(cf_matrix)\n",
    "\n",
    "\n",
    "# label dataframe \n",
    "df_cm = df_cm.rename(index   = {0: \"<=50k\", 1: \">50k\"}, # label rows\n",
    "                     columns = {0: \"<=50k\", 1: \">50k\"}) # label columns\n",
    "# plot \n",
    "plt.figure(figsize = (10,7))                     # set figure size\n",
    "sns.set(font_scale=1.4)                          # set label size\n",
    "\n",
    "# specify heat map\n",
    "sns.heatmap(df_cm,                               # specify dataframe                          \n",
    "           annot=True,                           # display data values       \n",
    "           annot_kws={\"size\": 16},               # format data values\n",
    "           fmt='g')                              # format values as \"general\"      \n",
    "\n",
    "# labels \n",
    "plt.title(\"Confusion Matrix\")                    # label title\n",
    "plt.xlabel(\"Predicted Label\")                    # label x axis\n",
    "plt.ylabel(\"True Label\")                         # label y axis     \n",
    "plt.show()                                       # show label                                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Authored by Aniket Kesari. Updated by Tom van Nuenen in 2022."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
