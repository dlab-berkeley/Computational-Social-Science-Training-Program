{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science] \n",
    "## 2-1 Math Fundamentals - Student Version\n",
    "\n",
    "This lab will provide an introduction to numpy and scipy libraries in Python. \n",
    "\n",
    "---\n",
    "\n",
    "### Topics Covered\n",
    "- Numpy Array\n",
    "- Numpy matrix\n",
    "- Local minima/maxima\n",
    "- Scipy optimize\n",
    "- Scipy integrate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Numpy <a id='section 1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy uses its own data structure, an array, to do numerical computations. The Numpy library is often used in scientific and engineering contexts for doing data manipulation.\n",
    "\n",
    "For reference, here's a link to the official [Numpy documentation](https://docs.scipy.org/doc/numpy/reference/routines.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy Arrays\n",
    "\n",
    "Arrays can hold many different data types, which makes them useful for many different purposes. Here's a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of intergers\n",
    "sample_list = [1, 2, 3]\n",
    "\n",
    "# create an array from a list\n",
    "sample_array = np.array(sample_list)\n",
    "\n",
    "# print  \n",
    "print(sample_list)\n",
    "print(sample_array) # notice array does not have \",\" separating elements like in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to make an array with three different arrays 1-3, 4-6, and 7-9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of three lists \n",
    "sample_list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "\n",
    "# create a nested array \n",
    "sample_array = np.array(sample_list)\n",
    "\n",
    "# print out results\n",
    "print(sample_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this operation do? What is the data type returned every time the \">\" is evaluated, and why is it important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we think this does?\n",
    "sample_array > 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can we evaluate elements in Python list?\n",
    "sample_list > 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix\n",
    "\n",
    "A **matrix** is a rectangular array. In Python, it looks like an array of arrays. We say that a matrix $M$ has shape **$m$x$n$**; that is, it has $m$ rows (different smaller arrays inside of it) and $n$ columns (elements in each smaller matrix). \n",
    "\n",
    "Matrices are used a lot in machine learning to represent sets of features and train models. Here, we'll give you some practice with manipulating them.\n",
    "\n",
    "Start by creating an empty matrix (filled with 0s) with dimensions 10 x 2. **Hint**: Look up the documentation for numpy's \"zeros\" method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **identity matrix** is a square matrix (i.e. size $n$x$n$) with all elements on the main diagonal equal to 1 and all other elements equal to zero. Make one below using `np.eye(n)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity matrix I of dimension 4x4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some matrix manipulation. Here are two sample matrices to use for practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample matrices\n",
    "m1 = np.array([[1, 3, 1], [1, 0, 0]])\n",
    "m2 = np.array([[0, 0, 5], [7, 5, 0]])\n",
    "\n",
    "# print results\n",
    "print(\"matrix 1 is: \\n\", m1)\n",
    "print(\"matrix 2 is: \\n\", m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add two matrices together if they have the same shape. Add our two sample matrices using the `+` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum the two matrices\n",
    "_ + _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every value in a matrix can also be multiplied by a single number, also called a **scalar**. Multiply one of the example matrices by a number using the `*` operator and see what it outputs. Note: this is not to be confused with matrix multiplication, which is generally associated with finding the dot product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale matrix 1 (m1) by 3\n",
    "_ * _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can sum all the elements of a matrix using `.sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sum of all of the elements in matrix 1\n",
    "_._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can get the average of the elements with `.mean()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean of all elements in matrix 2\n",
    "_._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is necessary to **transpose** a matrix to perform operations on it. When a matrix is transposed, its rows become its columns and its columns become its rows. Get the transpose by calling `.T` on a matrix (note: no parentheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transpose matrix 1\n",
    "_._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other times, you may need to rearrange an array of data into a particular shape of matrix. Below, we've created an array of 16 numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an array of numbers, which we will then reshape into a matrix\n",
    "H = np.arange(1, 17) # note that the method is exclusive\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.reshape()` on H to change its shape. `.reshape()` takes two arguments: the first is the desired number of rows, and the second is the desired number of columns. Try changing H to be a 4x4 matrix.\n",
    "\n",
    "*Note: if you try to make H be a 4x3 matrix, Python will return an error. Why?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make H a 4x4 matrix\n",
    "H = H.reshape(_ , _)\n",
    "H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's find the transpose of matrix H."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose matrix H and assign it the object name: H_t \n",
    "H_t = _._\n",
    "H_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll talk about **matrix multiplication**. The [dot product](https://en.wikipedia.org/wiki/Matrix_multiplication#Matrix_product_.28two_matrices.29) gets used a lot in optimization problems, among other things. It takes two matrices (one $m$x$n$, one $n$x$p$) and returns a matrix of size $m$x$p$. For example, the product of a 2x3 matrix and a 3x4 matrix is a 2x4 matrix.\n",
    "\n",
    "Note: to use the dot product, the two matrices must have the same number of elements. Additionally, the number of *columns* in the first matrix must equal the number of *rows* in the second matrix. This is why it's important to know how to reshape and transpose matrices!\n",
    "\n",
    "So, we can find the dot product of a 2x**3** matrix and a **3**x4 matrix because the number of columns in the first are equal to the rows of the second. \n",
    "\n",
    "You can use the dot product in numpy with `matrix1.dot(matrix2)` or `matrix1 @ matrix2`.\n",
    "\n",
    "A property of the dot product is that the product of a matrix and the identity matrix is just the first matrix. Check that that is the case below for the matrix `H`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: view the H matrix\n",
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: create and view an identity matrix (I)\n",
    "I = np.eye(4)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: find the dot product of H and I\n",
    "print(H.dot(I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, remember that using the `*` operator conducts element-wise mulitiplication, which is not the same as finding the dot product. Instead the dot product is a more complicated procedure whereby you mutiply row elements in the first matrix by the corresponding columns elements in the second and sum their products. Here is a simple but dry [primer on the dot product](https://www.youtube.com/watch?v=87_7YVCnAOw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# element-wise multiplication\n",
    "print(H * I)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How is the matrix product different from simply multiplying two matrices together?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix inverse\n",
    "##### Theorem: the product of a matrix m and its inverse is an identity matrix\n",
    "\n",
    "Using the above theorem, to solve for x in Ax=B where A and B are matrices, what do we want to multiply both sides by?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here: $A^{-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get the inverse of a matrix with `np.linalg.inv(my_matrix)`. Try it in the cell below.\n",
    "\n",
    "Note: not all matrices are invertible. For those curious, here is a short primer on [calculating the inverse of a matrix](https://www.youtube.com/watch?v=01c12NaUQDw)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new matrix from scratch, and call it m3\n",
    "m3 = np.array([[1, 0, 0, 0], [0, 2, 0, 0], [0, 0, 3, 0], [0, 0, 0, 4]])\n",
    "\n",
    "# calculate the inverse of m3 using the numpy method linalg.inv()\n",
    "m3_inverse = np.linalg.inv(m3)\n",
    "\n",
    "# print results\n",
    "print(\"matrix m3:\\n\", m3)\n",
    "print(\"\\ninverse matrix m3:\\n\", m3_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do we get the identity matrix?\n",
    "m3_inverse.dot(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "In machine learning, we often try to predict a value or category given a bunch of data. The essential model looks like this:\n",
    "\n",
    "$$ \\large\n",
    "Y =  X^T \\theta\n",
    "$$\n",
    "\n",
    "Where $Y $ is the predicted values (a vector with one value for every row of X)), $X$ is a $m$x$n$ matrix of data, and $\\theta$ (the Greek letter 'theta') is a **parameter** (an $n$-length vector). For example, X could be a matrix where each row represents a person, and it has two columns: height and age. To use height and age to predict a person's weight (our $y$), we could multiply the height and the age by different numbers ($\\theta$) then add them together to make a prediction($y$).\n",
    "\n",
    "The fundamental problem in machine learning is often how to choose the best $\\theta$. Using linear algebra, we can show that the optimal theta is:\n",
    "\n",
    "$$\\large\n",
    " \\hat{\\theta{}} = \\left(X^T  X\\right)^{-1} X^T Y\n",
    "$$\n",
    "\n",
    "This problem specification should look familiar to you - it is the same as regression! As we'll see in the coming weeks, you have already been exposed to many machine learning algorithms in your introductory statistics courses. The problem of estimating a model is the same, and the difference will mainly come in framing the ultimate goal of the model.\n",
    "\n",
    "You now know all the functions needed to find theta. Use transpose, inverse, and matrix product operations to calculate theta using the equation above and the X and y data given below. \n",
    "*Note that the equation above is expecting dot products of matrices, not element-wise multiplication!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility \n",
    "np.random.seed(seed = 7)\n",
    "\n",
    "# create an array of random numbers between 0 through 50 and add some random noise\n",
    "y = np.arange(50)+ np.random.normal(scale = 10,size=50)\n",
    "y\n",
    "\n",
    "# create a 50 element array and transpose it. How can we transpose this array?\n",
    "x = np.array([np.arange(50)])._\n",
    "x\n",
    "\n",
    "# to that array, add a a column of ones to represent an intercept term\n",
    "X = np.hstack([x, np.ones(x.shape)])\n",
    "X\n",
    "\n",
    "# let's use the formula above to find the best theta\n",
    "# hint: use np.linalg.inv to get the inverse and plug in the normal equation above\n",
    "theta = ...\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, our X is a matrix where the first column has values representing a feature, and the second column is entirely ones to represent an intercept term. This means our theta is a vector [m, b] for the equation $y=mx+b$, which you might recognize from algebra as the equation for a line (where $m$ is the slope of the line and $b$ is the intercept). Let's see how well our predictor line fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries and use magic fuction for formatting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#plot the data\n",
    "plt.scatter(x.T,y)\n",
    "\n",
    "# plot the fit line\n",
    "plt.plot(x.T[0], X @ theta);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "While it's good to know what computation goes into getting optimal parameters, it's also good that `sklearn` has a function that will take in an X and a y and return the best theta. Run the cell below to use `scikit-learn` to estimate the parameters. It should output values very near to the ones you found. We'll learn how to use `scikit-learn` in the next lab! \n",
    "\n",
    "But just a check, the below code runs uses the same data and fits a linear regression. Do we get the same results when we did calcualted it manually?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find optimal parameters using linear regression model\n",
    "# import linear model from sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# initialize the model fit and set to lin_reg  object \n",
    "lin_reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "\n",
    "# fit a linear model to x and y arrays\n",
    "lin_reg.fit(x, y)\n",
    "\n",
    "# print the coefficients and intercept\n",
    "print(lin_reg.coef_[0], lin_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maxima and Minima <a id='section 2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extrema of a function are the largest value (maxima) and smallest value (minima) of the function.\n",
    "\n",
    "We say that f(a) is a **local maxima** if $f(a)\\geq f(x)$ when x is near a.\n",
    "\n",
    "We say that f(a) is a **local minima** if $f(a)\\leq f(x)$ when x is near a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global vs local extrema (credit: Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Extrema_example_original.svg/440px-Extrema_example_original.svg.png\" style=\"width: 500px; height: 275px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the diagram , how are local maxima and minima of a function related to its derivative? Remember that the derivative of a function represents its slope at a particular value of x. What is the slope at a functions minima and maxima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are global maxima also local maixma? Are local maxima global maxima?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOUR ANSWER**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Intro to Scipy <a id='section 3'></a>\n",
    "\n",
    "The following part of this notebook is optional. We won't be taking a lot of derivatives in this course, but we reintroduce them to motivate your understanding of **optimization**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derivatives are essential for understanding some of the methods we'll be learning soon, including gradient descent, neural networks, and regularized regression methods. More broadly, most machine learning learning applications are best thought of as **optimization problems** where we are trying to minimize a **cost function**. More simply, we want to minimize our prediction errors.\n",
    "\n",
    "`scipy.optimize` is a package that provides several commonly used optimization algorithms. Today we'll learn minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing minimize function\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a minimization problem:\n",
    "\n",
    "minimize $x_1x_4(x_1+x_2+x_3)+x_3$ under the conditions:\n",
    "1. $x_1x_2x_3x_4\\geq 25$\n",
    "2. $x_1+x_2+x_3+2x_4 = 14$\n",
    "3. $1\\leq x_1,x_2,x_3,x_4\\leq 5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, looks fairly complicated, but don't worry, scipy's got it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define our function\n",
    "def objective(x):\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "    x3 = x[2]\n",
    "    x4 = x[3]\n",
    "    return x1*x4*(x1+x2+x3)+x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define constraints 1 and 2\n",
    "def con1(x):\n",
    "    return x[0]*x[1]*x[2]*x[3] - 25\n",
    "def con2(x):\n",
    "    return 14 - x[0] - x[1] - x[2] - 2*x[3]\n",
    "\n",
    "constraint1 = {'type': 'ineq', 'fun': con1}  # constraint 1 is an inequality constraint\n",
    "constraint2 = {'type': 'eq', 'fun': con2}    # constraint 2 is an equality constraint\n",
    "\n",
    "cons = [constraint1, constraint2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define bounds, which is constraint 3\n",
    "bound = (1, 5)\n",
    "bnds = (bound, bound, bound, bound) #the same bound applies to all four variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to supply initial values as a starting point for minimize function\n",
    "x0 = [3, 4, 2, 3]\n",
    "print(objective(x0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, we defined objective function, constraints, bounds, and initial values. Let's get to work.\n",
    "\n",
    "We'll use [Sequential Least Squares Programming optimization algorithm (SLSQP)](http://www.pyopt.org/reference/optimizers.slsqp.html). Check out the documentation for the [`minimiuze()` method](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) to see possible parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = minimize(objective, x0, method='SLSQP', bounds=bnds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display optimal values of each variable\n",
    "print(solution.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Find the optimal solution to the following problem:\n",
    "\n",
    "minimize $x1^2+x2^2+x3^2$, under conditions:\n",
    "1. $x1 + x2\\geq 6$\n",
    "2. $x3 + 2x2\\geq 4$\n",
    "3. $1.5\\leq x1, x2, x3\\leq 8$\n",
    "\n",
    "Tip: 3**2 gives square of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    _ = _\n",
    "    _ = _\n",
    "    _ = _\n",
    "    return _\n",
    "def newcon1(x):\n",
    "    return _ + _ - _\n",
    "def newcon2(x):\n",
    "    return _ + _ - _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note of scipy's documentation on constraints:\n",
    "\n",
    "> \"Equality constraint means that the constraint function result is to be zero whereas inequality means that it is to be non-negative.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcons1 = {'type': 'ineq', 'fun': newcon1}\n",
    "newcons2 = {'type': 'ineq', 'fun': newcon2}\n",
    "newcons = [newcons1, newcons2]\n",
    "bd = (_, _)\n",
    "bds = (_, _, _)\n",
    "newx0 = [_, _, _]\n",
    "\n",
    "\n",
    "sum_square_solution = minimize(_)\n",
    "sum_square_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last concept we'll introduce is **integration**. You can think of integration as the reverse operation of a derivative. One common application of the integral is finding the area under a curve. Let's take a look:  \n",
    "\n",
    "`scipy.integrate.quad` is a function that integrates a function from a to b using a technique from QUADPACK library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing integrate package\n",
    "from scipy import integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple function\n",
    "def f(x):\n",
    "    return np.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate sin from 0 to pi\n",
    "integrate.quad(f, 0, np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our quad function returned two results, first one is the result, second one is an estimate of the absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Find the integral of $x^2 + x$ from 3 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the function\n",
    "def f1(x):\n",
    "    return _\n",
    "\n",
    "\n",
    "#find the integral\n",
    "integrate.quad(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrate a normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within statistics, integration is important because it is related to the way we convert a **probability density function** to a **cumulative distribution function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a normal distribution with mean 0 and standard deviation 1 by simpy running the cell\n",
    "mu, sigma = 0, 1\n",
    "s = np.random.normal(mu, sigma, 100000)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "count, bins, ignored = plt.hist(s, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *np.exp( - (bins - mu)**2 / (2 * sigma**2) ),linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing normal d\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CDF is cumulative distribution function. CDF(x) is the probability that a normal distribution takes on value less than or equal to x.\n",
    "\n",
    "For a standard normal distribution, what would CDF(0) be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to confirm your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the cdf, integrate the normal distribution from -0.5 to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(.5) - norm.cdf(-.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the relationship between a probability distribution and a p-value? **Hint**: What is the CDF in the tails of the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: What values do we get here? What do they mean?\n",
    "print(norm.cdf(-1.65))\n",
    "print(1 - norm.cdf(1.65))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Materials for this notebook were based on the notebook developed by Tian Qin for [Legal Studies 123: Data, Prediction, and Law](https://github.com/Akesari12/LS123_Data_Prediction_Law_Spring-2019)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
