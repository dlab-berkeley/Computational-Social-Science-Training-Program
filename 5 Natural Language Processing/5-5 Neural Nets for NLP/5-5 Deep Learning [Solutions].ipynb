{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlab-berkeley/Computational-Social-Science-Training-Program/blob/master/Deep_Learning_and_Tensorflow_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DrTKxZ1hCS5"
      },
      "source": [
        "# [Computational Social Science]\n",
        "## 5-5 Deep Learning - Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHoISf71wzH2"
      },
      "source": [
        "This notebook will introduce you to the fundamentals of Keras and explore techniques for deep learning with text data. Key concepts covered in this notebook include:\n",
        "\n",
        "1. Google Colab and GPUs\n",
        "2. Use keras to adapt and tune neural nets\n",
        "3. Existing resources to help analyze language data\n",
        "\n",
        "\n",
        "With these basic building blocks, you will be equipped to explore and implement deep learning algorithms for your own project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNqj6s9msZga"
      },
      "source": [
        "# Google Colab\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNovoJcyugcM"
      },
      "source": [
        "Objectives:\n",
        "\n",
        "- Set up a Google Colab notebook\n",
        "- Create, delete, run, and edit cells\n",
        "- Cover variable, notebook and package management\n",
        "\n",
        "15 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_zANHRDhplZ"
      },
      "source": [
        "## Introducing Google Colab\n",
        "\n",
        "\n",
        "Google Colab is a platform for cloud-based computation and coding. It is similar to a Jupyter Notebook, where individual cells of code are executed sequentially. It doesn't require local installation on your computer and can be shared and edited by multiple people at the same time. However the Colab notebook requires you to be connected to the internet, while jupyter notebooks can be run on your local machine. Google Colab notebooks are in the .ipynb format, and can be saved and opened either directly or via Google Drive.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqx972vJvdVv"
      },
      "source": [
        "##Basic Operations\n",
        "\n",
        "Google Colab has several features that help organize code and long notebooks. A few key concept to know to use this notebook effectively are:\n",
        "\n",
        "- Use the Insert tab in the upper bar, or press the +Code/+Text buttons in the top left of the window.\n",
        "\n",
        "- Text cells can be edited and formatting with the buttons at the top of the cell.\n",
        "\n",
        "- The buttons at the top right of the cell give you options to move, modify and delete the cell.\n",
        "\n",
        "- You can run code with shift+enter, or by clicking the top left of the box.\n",
        "\n",
        "- For more commands, use ctl+shift+p and select the desired command from the command palette\n",
        "\n",
        "An example code cell is below. Try executing and editing the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vhl6KsHCrLP-"
      },
      "outputs": [],
      "source": [
        "print(\"Welcome to Google Colab\")\n",
        "x=12+78"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pT9L_Th9sPrV"
      },
      "source": [
        "The buttons on the left panel help manage the notebook (search, table of contents, files). This is important for organizing your code and navigating long notebooks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR9JpuTHcmVz"
      },
      "source": [
        "## Package Management\n",
        "\n",
        "Like Anaconda, Google Colab comes with many packages already available, and you can also install local packages using pip. Use the following lines of code in order to see which packages you have and which ones you need to install.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "#check which packages you have available (listed alphabetically). The version numbers are also avaliable which can be useful in determining issues with coding between computers.\n",
        "!pip list\n",
        "\n",
        "#install a new package\n",
        "!pip install numpy\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<List of packages that we will use in this tutorial>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ3GQZB7bo6M"
      },
      "source": [
        "In the following cell are the packages that you will need to complete this notebook. Run this line of code to make sure that everything is installed properly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Qey74xT0boGX"
      },
      "outputs": [],
      "source": [
        "#import packages for deep learning\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# from keras.utils import np_utils\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi2ikVCaoNct"
      },
      "source": [
        "## Customization\n",
        "\n",
        "Finally, there are several settings that you can customize if you so choose. These can be found under Tools -> Settings, where you can change the font size, background, and other aesthetic settings of the notebook to suit you.\n",
        "\n",
        "In addition, in Tools -> Keyboard shortcuts you can view and adapt shortcuts to your preferences as well.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHrAjcLHsYC3"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Try out the following exercises to get comfortable with the new interface:\n",
        "\n",
        "1) Open the editor settings (Tools-> Settings->Editor) and select \"Show line numbers\". Now your cells will have line numbers next to them, which we can refer to when discussing code during this workshop.\n",
        "\n",
        "2) Make a new code cell below and save the product of 60 and 72 to a new variable. Then check the value of the variable in the variable tab to the left.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2iLcnJj1-Ng"
      },
      "outputs": [],
      "source": [
        "#solutions\n",
        "#1) follow the directions in the question. You should see the line numbers in\n",
        "# each cell on the left side\n",
        "#2)\n",
        "new = 60*72 #check the value of this variable using the variable panel on the left"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A58nCiMsshpn"
      },
      "source": [
        "# Introduction to GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1AkXBaoujUc"
      },
      "source": [
        "Objectives:\n",
        "- Understand the benefits of GPUs\n",
        "- Set up GPU for Google Colab\n",
        "- Compare performance on tasks vs CPU\n",
        "\n",
        "\n",
        "10 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp2UXU5HHTSM"
      },
      "source": [
        "As you've found in your previous models, some models take a significant amount of time to run. Models may also exceed the capacity of the local computer's processing power. This will either result in code that never finished running, or an error message indicating that the code has timed out without completing.\n",
        "\n",
        "To counteract this issue, TPU/GPU are parallel processing units that greatly speed up models. This can make some models that are otherwse impossible to train possible (Think minutes rather than hours)\n",
        "\n",
        "TPU is made specifically for tensorflow architecture, and speeds it up even more than GPUs.\n",
        "\n",
        "## GPU Access\n",
        "Oftentimes you need to pay for cloud services and access to GPUs, but one advantage of Colab is that it has free access to a certain amount of GPU/TPU units. This access is somewhat limited, but should be more than enough for what we are using it for today. We will discuss limitations and further options for long-term use in a later section of the workshop.\n",
        "\n",
        "\n",
        "Additional resource: https://colab.research.google.com/notebooks/gpu.ipynb#scrollTo=sXnDmXR7RDr2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co9jxID0Utsj"
      },
      "source": [
        "The notebook will automatically choose which device (read: GPU vs CPU) to run the code on, but if you want to make sure that something is being run on a certain device, you can select a specific device as in the snippet below.\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "with tf.device(device_name):\n",
        "  #put task here\n",
        "  #return output\n",
        "```\n",
        "\n",
        "For now, we will trust the notebook's/ Tensorflow's allocation of computing power.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9xyYBVVRZlE"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "1) Run the following lines of code to test how fast your computer can do a task. Report the results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqgQQ2a1SBDj",
        "outputId": "2e023e5b-9aa6-400d-d9cd-34e2ac43f973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.5632765139999947\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx9qArhdR-31"
      },
      "source": [
        "2)  Change the settings to use GPU:  Edit --> Notebook Settings --> Hardware Accelerator --> GPU\n",
        ". Run the code below to make sure GPU is enabled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow0GhY3ANepm",
        "outputId": "1d252fd7-ac44-4cc8-d1c0-6c7df24b408d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "#run this code to check that you have the GPU enabled\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6kl-9FvVbBD"
      },
      "source": [
        "3) Re-run the same timing task and report your results. How much of a difference is there in timing?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9ADVC5SVabz",
        "outputId": "44e80fd7-5906-453f-9fc0-763f09232c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6405670770000143\n"
          ]
        }
      ],
      "source": [
        "import timeit\n",
        "print(timeit.timeit('[x**2 for x in range(10)]'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GvtUiHVV6IO"
      },
      "source": [
        "As we run more complex tasks, the efficiency of GPUs becomes more and more of a difference. If you are curious, you can compare the timing of the tasks in this notebook with GPU/TPU/CPU and note the difference. Even though in this notebook we are working with fairly small dataset and task, these differences will be important at larger scale."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TR78IdDij7M"
      },
      "source": [
        "# Deep Learning\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6twFHgyZSeiv"
      },
      "source": [
        "Objectives:\n",
        "- Code and optimize a neural network\n",
        "- Adapt a network to new data\n",
        "\n",
        "20 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRq8wjQaqiWW"
      },
      "source": [
        "In previous sections of this course, you have covered neural networks and deep learning for classifying the MNIST dataset. The task was classifying handwritten digits 0-9 based on images. In this section, we will revisit deep learning in Python with text data.\n",
        "\n",
        "We will start with the classificaton problem (student loan vs checking/savings account) from the NLP section of the course, where customer complaint data was used classify what type of account the complaint was related to. We will use the same embeddings we trained for the final logistic regression problem in that section of the course.\n",
        "\n",
        "First, we will load in the data and split it into training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "bMyrg9cv0pDS"
      },
      "outputs": [],
      "source": [
        "word2vec_features_df=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/embeddings.csv').iloc[:, 1:]\n",
        "y=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df,\n",
        "                                                    y_vals,\n",
        "                                                    train_size = .80,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state = 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhyFnEKUh_uz"
      },
      "source": [
        "We will use Keras now. Keras is a widely-used high-level neural network API known for its simplicity and quick prototyping capabilities. While it was originally an independent project that could operate with various backends such as Theano and CNTK, TensorFlow has emerged as its primary backend. This integration allows Keras to take advantage of TensorFlow's powerful features, including its ability to run smoothly on different hardware like CPUs, GPUs, and TPUs. By utilizing TensorFlow as its underlying engine, Keras simplifies many complex aspects of deep learning, making the development of neural networks more accessible. Its user-friendly nature has led to extensive use in both industrial applications and academic research.\n",
        "\n",
        "Next we define the model. In Keras, each layer of the model has to be individually specified. This allows significant control over the model, including different parameters for each level.\n",
        "\n",
        "This model has a dense layer with 128 neurons in each, and a dropout layer where 20% of the connections are dropped out for each layer. The final output layer uses a sigmoid activation function to create a final binary output (0 or 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "colGv5dcuzwP"
      },
      "outputs": [],
      "source": [
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, input_dim=300,activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # An output layer with binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model with crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wH5KqiKiQQl"
      },
      "source": [
        "Finally, we fit and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AXKsZQwVsR",
        "outputId": "4b5c369a-bf2e-4419-ad23-d354d31f2b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Error: 21.50%\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 128)               38528     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 38657 (151.00 KB)\n",
            "Trainable params: 38657 (151.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=0)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIN6sK82FQxp"
      },
      "source": [
        "This is a simple neural network with a couple of densely connected layers and a couple of dropout layers. When working with neural nets, it's often a good idea to start with a simple net to make sure the basics of the code work, then gradually create more complicated architectures once the code runs smoothly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGLS9pEUibTB"
      },
      "source": [
        "Now, let's use our tensor knowledge to adapt this architecture to another set of data. First, let's load in the MNIST digits dataset (in practice, we would likely be using a dataset more similar to the one in the original model). The MNIST dataset is three dimensions (n_samplesx28x28), so we need to flatten the data for now to create a two dimensional tensor  n_samplesx784 to fit with the neural net we are working on. Note: instead of two classes, the MNIST dataset uses 10 classes (one for each digit 0-9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "jZTIeDTnBn8o"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# reshape to [samples][width][height][pixels]\n",
        "X_train = X_train.reshape(X_train.shape[0], 28*28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28*28)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bP926VQjIJ6"
      },
      "source": [
        "Here is the same code from the NN model above. What do you need to change in order to run the same model on the new data? Note which parameters and values you need to change. How does this relate to the differences in the data? Let's edit the code to work with the new data shape and execute it.\n",
        "\n",
        "Hint: use tf.shape() to see the compare the shapes of the MNIST and original dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DtWkyXLfNbk"
      },
      "source": [
        "These are the lines of code we need to change to make this model work with new data:\n",
        "\n",
        "\n",
        "In line 6:\n",
        "```\n",
        "model.add(Dense(128, input_dim=784,activation='relu')) #change input dim\n",
        "```\n",
        "The embeddings dataset had 300 features, or columns, the new MNIST dataset has 784, so we need to make sure to match the numbers in model architecture.\n",
        "\n",
        "In line 12:\n",
        "\n",
        "```\n",
        "    model.add(Dense(10, activation='softmax')) #change dimension to number of categories\n",
        "```\n",
        "The final layer needs to have 10 categories, rather than two, since there are more classes in the MNIST dataset. In addition, the activation function needs to be changed to softmax.\n",
        "\n",
        "In lne 15:\n",
        "\n",
        "```\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "\n",
        "Again, because of the number of classes, the loss function used must be categorical cross entropy rather than binary cross entropy.\n",
        "\n",
        "Here is the updated model:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsgLoMccgRtr",
        "outputId": "132d50c1-7464-4212-eb6d-bc05c3c6decc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "Epoch 1/10\n",
            "300/300 - 2s - loss: 5.2501 - accuracy: 0.6533 - val_loss: 0.7492 - val_accuracy: 0.8283 - 2s/epoch - 7ms/step\n",
            "Epoch 2/10\n",
            "300/300 - 1s - loss: 0.9208 - accuracy: 0.7827 - val_loss: 0.5430 - val_accuracy: 0.8724 - 891ms/epoch - 3ms/step\n",
            "Epoch 3/10\n",
            "300/300 - 1s - loss: 0.6803 - accuracy: 0.8351 - val_loss: 0.4452 - val_accuracy: 0.8939 - 895ms/epoch - 3ms/step\n",
            "Epoch 4/10\n",
            "300/300 - 1s - loss: 0.5580 - accuracy: 0.8616 - val_loss: 0.3704 - val_accuracy: 0.9176 - 880ms/epoch - 3ms/step\n",
            "Epoch 5/10\n",
            "300/300 - 1s - loss: 0.4781 - accuracy: 0.8818 - val_loss: 0.3551 - val_accuracy: 0.9178 - 1s/epoch - 4ms/step\n",
            "Epoch 6/10\n",
            "300/300 - 1s - loss: 0.4212 - accuracy: 0.8935 - val_loss: 0.3117 - val_accuracy: 0.9323 - 1s/epoch - 4ms/step\n",
            "Epoch 7/10\n",
            "300/300 - 1s - loss: 0.3684 - accuracy: 0.9053 - val_loss: 0.2657 - val_accuracy: 0.9401 - 890ms/epoch - 3ms/step\n",
            "Epoch 8/10\n",
            "300/300 - 1s - loss: 0.3358 - accuracy: 0.9144 - val_loss: 0.2481 - val_accuracy: 0.9430 - 833ms/epoch - 3ms/step\n",
            "Epoch 9/10\n",
            "300/300 - 1s - loss: 0.3052 - accuracy: 0.9203 - val_loss: 0.2432 - val_accuracy: 0.9444 - 871ms/epoch - 3ms/step\n",
            "Epoch 10/10\n",
            "300/300 - 1s - loss: 0.2782 - accuracy: 0.9248 - val_loss: 0.2293 - val_accuracy: 0.9465 - 824ms/epoch - 3ms/step\n",
            "NN Error: 5.35%\n"
          ]
        }
      ],
      "source": [
        "def diff_CNN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128, input_dim=784,activation='relu')) #change input dim\n",
        "\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "\n",
        "    model.add(Dense(10, activation='softmax')) #change dimension to number of categories and activation function\n",
        "\n",
        "    #change to categorical crossentropy\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "model = diff_CNN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23KhRlCwGLSi"
      },
      "source": [
        "# Optimizing Neural Nets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOPuwHOBSt2l"
      },
      "source": [
        "Objectives:\n",
        "- Explore strategies to optimize a neural net\n",
        "- Implement an optimizer with custom settings\n",
        "- Grid search parameters\n",
        "\n",
        "20 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZjXK0-OGT5C"
      },
      "source": [
        "Optimizing neural nets is a key point of using these powerful models effectively, as with any ML models. However, neural nets have many parameters that can be tuned and are a challenge for traditional optmization methods such as grid search.\n",
        "\n",
        "In the previous challenge, we experimented with improving the accuracy of the model. The following strategies can help guide the optmization process for fine-tuning algorithms.\n",
        "\n",
        "1. Feature engineering (refer to Natural Language Processing Notebook)\n",
        "\n",
        "2. Try a smaller network (minimize redundancy) or a larger network (capture more complex relationships)\n",
        "\n",
        "3. Change learning rate\n",
        "4. Use appropriate architecture for the data/task\n",
        "\n",
        "5. Test parameters\n",
        "\n",
        "6. Decrease batch size\n",
        "\n",
        "Depending on the task, data, and neural network used, there may be a significant amount of tuning necessary in order to achieve an optimal result. This is one reason why leveraging existing models that are already optimized can give a huge advantage for language tasks.\n",
        "\n",
        "Further reference this article: https://towardsdatascience.com/optimizing-neural-networks-where-to-start-5a2ed38c8345\n",
        "\n",
        "\n",
        "For this notebook we will start with changing the learning rate.\n",
        "\n",
        "In previous examples, we passed the optimizer to the compile funciton\n",
        "```\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "```\n",
        "Which uses the default parameters for the function. Now that we are customizing the parameters, we want to use the actual optimizer function, and then pass that optimizer into the .compile() function.\n",
        "\n",
        "```\n",
        "model.compile(....,opt=keras.optimizers.Adam())\n",
        "```\n",
        "\n",
        "Here is the documentation for that function: https://keras.io/api/optimizers/adam/\n",
        "\n",
        "What is the default parameter for learning rate? What are some of the other parameters for the Adam optimizer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElzhbM-eOPDe"
      },
      "source": [
        "##Challenge\n",
        "\n",
        "Test the following learning rates: [.0001,.001,.01,.1]. Which one performs the best? Which one performs the worst?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "9DZBPIH2OObp"
      },
      "outputs": [],
      "source": [
        "#load in data to use for this test\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#cnn classification for neural nets\n",
        "word2vec_features_df=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/embeddings.csv').iloc[:, 1:]\n",
        "\n",
        "y=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df,\n",
        "                                                    y_vals,\n",
        "                                                    train_size = .80,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state = 10)\n",
        "#print(word2vec_features_df.shape)\n",
        "#print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "h8LXyHanPz9V"
      },
      "outputs": [],
      "source": [
        "#solution\n",
        "##1\n",
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128, input_dim=300,activation='relu')) #change input dim\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "\n",
        "    # An output layer with softmax as in MLP\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    adam_opt=Adam(learning_rate=.1)\n",
        "    # Compile model as before in MLP\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam_opt, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trjy8DMSQCGj",
        "outputId": "1b92dc36-d8f4-40c4-bf38-a19e713a8e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 300)\n",
            "Epoch 1/10\n",
            "4/4 - 1s - loss: 0.8766 - accuracy: 0.7375 - val_loss: 0.5715 - val_accuracy: 0.7850 - 1s/epoch - 281ms/step\n",
            "Epoch 2/10\n",
            "4/4 - 0s - loss: 0.5343 - accuracy: 0.7862 - val_loss: 0.5404 - val_accuracy: 0.7850 - 37ms/epoch - 9ms/step\n",
            "Epoch 3/10\n",
            "4/4 - 0s - loss: 0.5328 - accuracy: 0.7812 - val_loss: 0.5218 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 4/10\n",
            "4/4 - 0s - loss: 0.5364 - accuracy: 0.7850 - val_loss: 0.5207 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 5/10\n",
            "4/4 - 0s - loss: 0.5191 - accuracy: 0.7862 - val_loss: 0.5186 - val_accuracy: 0.7850 - 37ms/epoch - 9ms/step\n",
            "Epoch 6/10\n",
            "4/4 - 0s - loss: 0.5184 - accuracy: 0.7862 - val_loss: 0.5177 - val_accuracy: 0.7850 - 35ms/epoch - 9ms/step\n",
            "Epoch 7/10\n",
            "4/4 - 0s - loss: 0.5225 - accuracy: 0.7862 - val_loss: 0.5094 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 8/10\n",
            "4/4 - 0s - loss: 0.5088 - accuracy: 0.7862 - val_loss: 0.5050 - val_accuracy: 0.7850 - 34ms/epoch - 8ms/step\n",
            "Epoch 9/10\n",
            "4/4 - 0s - loss: 0.5058 - accuracy: 0.7862 - val_loss: 0.4985 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "Epoch 10/10\n",
            "4/4 - 0s - loss: 0.4965 - accuracy: 0.7862 - val_loss: 0.4927 - val_accuracy: 0.7850 - 33ms/epoch - 8ms/step\n",
            "CNN Error: 21.50%\n"
          ]
        }
      ],
      "source": [
        "model = NN_model()\n",
        "# Fit the model\n",
        "print(X_train.shape)\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AXRqpHOqKxy"
      },
      "source": [
        "# Challenge: Optimizing a Neural Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZj0IiVYjYtY"
      },
      "source": [
        "\n",
        "The logit model from the challenge question in NLP section used to classify the customer complaint data had an accuracy of 78.5%. What is the accuracy of the first neural network model on the same data? Hint: (read the output) Try changing the model to improve accuracy. What configuration gave you the best results? Try changing the parameters of the existing layers, or adding more layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qSEW7T0Vpacv"
      },
      "outputs": [],
      "source": [
        "word2vec_features_df=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/embeddings.csv').iloc[:, 1:]\n",
        "y=pd.read_csv('https://github.com/dlab-berkeley/Computational-Social-Science-Training-Program/raw/main/data/y.csv')\n",
        "y_vals=y['Product_binary'].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(word2vec_features_df,\n",
        "                                                    y_vals,\n",
        "                                                    train_size = .80,\n",
        "                                                    test_size=0.20,\n",
        "                                                    random_state = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpMjqhdt3HKh",
        "outputId": "af0eef44-f217-4f69-9466-70d22fefe557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NN Error: 21.50%\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 128)               38528     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 55169 (215.50 KB)\n",
            "Trainable params: 55169 (215.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#original model\n",
        "\n",
        "def NN_model():\n",
        "    # create model\n",
        "    model = Sequential()\n",
        "\n",
        "    # A fully connected layer with 128 neurons\n",
        "    model.add(Dense(128, input_dim=300,activation='relu'))\n",
        "\n",
        "    # A dropout layer that randomly excludes 20% of neurons in the layer\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    # An output layer with binary classification\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model with crossentropy\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "    model = NN_model()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=0)\n",
        "\n",
        "# Evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(\"NN Error: %.2f%%\" % (100-scores[1]*100))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZEJquJOwESl"
      },
      "source": [
        "In practice we often take advantage of existing code and architecture to help accomplish deep learning tasks. This can range from taking a neural network architecture and adapting it to new data (as in our exercise above) to using other packages with pre-trained models. In the next section we will explore one such package called Huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Ovl5RF2DjS"
      },
      "source": [
        "# Huggingface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRXZt7DhS7mR"
      },
      "source": [
        "Objectives:\n",
        "- Explore tasks and data available in Huggingface transformers\n",
        "- Choose an appropriate language task\n",
        "- Implement a transformer on local data\n",
        "\n",
        "20 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glKdUE_CEw7h"
      },
      "source": [
        "In reality, these models  require significant data and computational power, which can exceed the resources available to the analyst. We can circumvent this problem by using pre-trained models. Like a pre-trained embedding model, pre-trained models are trained on a large dataset. While this may not perfectly align with the data or task you have, it can help create a more robust system that can be fine-tuned to your data and goals.\n",
        "\n",
        "[Huggingface](https://huggingface.co/models) is a set of pretrained models from a variety of datasets and sources with an easy-to-use interface. In this section, we will explore the use of the Huggingface library to streamline language task processing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE52xADz3Py-",
        "outputId": "14516da7-e995-4b3d-cfce-f50ddddb13c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "#install the transformers library\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WygeyX2MQo8T"
      },
      "source": [
        "The simplest strategy is to use the pipeline method, where you select the task and the pre-trained model (there are multiple models available for many of the tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9pq4nvXSnMh",
        "outputId": "fff2ef89-6427-46af-8987-df98c3fb6f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"sentiment-analysis\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdXQGdLgQ9sa"
      },
      "source": [
        "The key to using these models, since the preprocessing is built in, is understanding the format of the data necessary for the model. This model takes the raw text as input rather than the word embeddings, so let's reload our data appropriately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iahhf3AEUGBN",
        "outputId": "9cbccf4d-462b-421b-d245-a3e78b695aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewed my credit report in XX/XX/XXXX and noticed a lot of errors, inconsistent, and incorrect information. Sent a letter to Equifax on XX/XX/XXXX via mail asking them for an investigation and to verify all the dates and amounts were correct and fix the incorrect reporting on my credit. They did not respond at all so I sent another letter on XX/XX/XXXX via mail, again asking for an investigation and proof. They still didnt respond to that letter so I sent a third letter on XX/XX/XXXX certified mail so I have proof that they signed for my letter.\n",
            "\n",
            "Last week I received two letters from Equifax dated XX/XX/XXXX on the same day. The said that they could not locate my credit file and needed me to send proof of identification and address. With all three letters I sent a copy of my Arizona drivers license and my XXXX direct deposit sub as my proof of address. The second letter said that they received my request to be removed from the promotions list and that it was added to my credit file. How did they find my file to add the restriction if they couldnt find my credit file in regards to investigation purposes?\n"
          ]
        }
      ],
      "source": [
        "cfpb=pd.read_csv('https://raw.githubusercontent.com/dlab-berkeley/Computational-Social-Science-Training-Program/main/data/CFPB%202020%20Complaints.csv')\n",
        "complaints=cfpb['Consumer complaint narrative']\n",
        "complaints=complaints[~complaints.isna()]\n",
        "classifier(complaints.values[0])\n",
        "print(complaints.values[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_rQGYoPRNon"
      },
      "source": [
        "Then use the pipeline on the example data, and look at the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Thjw7tTaRSgH",
        "outputId": "49bd35d6-e39d-471e-b067-b40da73a5d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviewed my credit report in XX/XX/XXXX and noticed a lot of errors, inconsistent, and incorrect information. Sent a letter to Equifax on XX/XX/XXXX via mail asking them for an investigation and to verify all the dates and amounts were correct and fix the incorrect reporting on my credit. They did not respond at all so I sent another letter on XX/XX/XXXX via mail, again asking for an investigation and proof. They still didnt respond to that letter so I sent a third letter on XX/XX/XXXX certified mail so I have proof that they signed for my letter.\n",
            "\n",
            "Last week I received two letters from Equifax dated XX/XX/XXXX on the same day. The said that they could not locate my credit file and needed me to send proof of identification and address. With all three letters I sent a copy of my Arizona drivers license and my XXXX direct deposit sub as my proof of address. The second letter said that they received my request to be removed from the promotions list and that it was added to my credit file. How did they find my file to add the restriction if they couldnt find my credit file in regards to investigation purposes?\n",
            "[{'label': 'NEGATIVE', 'score': 0.9993847608566284}]\n",
            "TransUnion has not properly investigated the items below. I am requesting they be removed from my report pending a thorough review. \n",
            "\n",
            "ACCOUNTS XXXX XXXX XXXX XXXX not mine XXXX XXXX XXXX XX/XX/2018 unauthorized XXXX XXXX XX/XX/2018 unauthorized XXXX  XXXX XX/XX/2018 unauthorized XXXX XXXX XXXX XX/XX/2018 unauthorized XXXX  XXXX I XX/XX/2018 unauthorized XXXX XXXX XXXX XX/XX/2018 unauthorized XXXX XXXX XXXX XX/XX/2018 unauthorized XXXX XXXX XXXX XXXX not mine\n",
            "[{'label': 'NEGATIVE', 'score': 0.9992923736572266}]\n",
            "XX/XX/2020 someone tried to steal my identity by opening up a credit card with XXXX  XXXX XXXX and XXXX XXXX XXXX XXXX XXXX and XXXX XXXXXXXX  XXXX ran a hard inquiry XXXX and XXXXXXXX XXXX XXXX  has since been removed from my credit report. Transunion and XXXX  are refusing to remove the XXXX XXXX hard inquiry. I have a letter from XXXX XXXX stating that Transunion and XXXX are to remove that hard inquiry because it consisted of fraud. Thank you. \n",
            "XXXX XXXX.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9986603260040283}]\n",
            "I paid the debt on XX/XX/XXXX. I disputed account on credit report on XX/XX/XXXX. Dispute report was finalized on XXXX nothing changed even after presenting supporting documentation. The account still showing incorrect balance.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9974887371063232}]\n",
            "A COLLECTION HAS BEEN REPORTED TO MY CREDIT REPORT THAT IS NOT MINE.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9996302127838135}]\n",
            "this collection is not mines\n",
            "[{'label': 'POSITIVE', 'score': 0.9877626895904541}]\n",
            "I recently reviewed my credit profile and noticed inaccuracies and false accusations and fraudulent accounts.\n",
            "[{'label': 'NEGATIVE', 'score': 0.995735764503479}]\n",
            "Ive been cosistent paying my bills on time. I'm saying this because I went XXXX XXXX the other day and applied for an account. I got approved but with a {$400.00} deposit. I dint understand until I checked my credit report. I see a couple of items that are not mine. These items need to be deleted from my credit report.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9988757967948914}]\n",
            "I sent in requests to investigate errors on my credit report over 30 days ago, but I have not yet received the response. They were supposed to respond within 30 days, but they have not.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9987154006958008}]\n",
            "I requested for items to be investigated via mail and they have refused to perform the investigation. \n",
            "Please delete the items on the attached letter from my credit report.\n",
            "[{'label': 'NEGATIVE', 'score': 0.9994825124740601}]\n"
          ]
        }
      ],
      "source": [
        "for k in range(10):\n",
        "  print(complaints.values[k])\n",
        "  print(classifier(complaints.values[k]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGFiOhimXOYq"
      },
      "source": [
        "As you might expect, the complaints dataset has mostly negative values. While this is somewhat of a trivial example, it highlights how in just a few lines of code and no preprocessing we can implement a model on our own data. While this doesn't work for every task, for example the specific classification task that we were working with above, this is a valuable and powerful tool for quick, out-of-the-box models that don't take very long to initialize and tune."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPEso9g_CP0b"
      },
      "source": [
        "# Large Language Model\n",
        "We can use a large language model such as GPT-2 or GPT-Neo with the Hugging Face Transformers library. In this example, we will generate text using the GPT-2 model with the Hugging Face Transformers library. This example will use the code below to produce five different continuations of the provided input text.\n",
        "\n",
        "We will use pipeline function. The pipeline function is a simple way to create a model with its associated preprocessing and postprocessing steps.  It's a high-level function provided by the Hugging Face Transformers library that makes it easy to load a pre-trained model with its associated tokenizer and use it for various tasks like text generation, sentiment analysis, and more. Using the pipeline function is not strictly necessary, but it does simplify the code by abstracting away several underlying details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "erG8u-0GCP0b"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "# Here, 'text-generation' tells the pipeline to create a text generation model, and model='gpt2'\n",
        "# specifies that you want to use the GPT-2 model for this task.\n",
        "generator = pipeline('text-generation', model='gpt2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVHXk8GGCP0b",
        "outputId": "8387de45-a9ee-4efd-95f0-55047297c506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I study sociology at University of California-Davis, U.S.A. and are working on a thesis on the relationship between gender roles and college students with ADHD. This article will discuss the research and current policy that has enabled me to use the\n",
            "----\n",
            "I study sociology at University of California Irvine. She writes:\n",
            "\n",
            "\"As a sociology major, I have a passion for learning, both for people and to make research decisions.\" A graduate student, she holds a graduate degree in anthropology from University of\n",
            "----\n",
            "I study sociology at University of California, Santa Barbara, where I worked as the director of the student-run \"Papers on the Web.\"\n",
            "\n",
            "I found myself talking to people who were living in the real world at a time when their voices\n",
            "----\n",
            "I study sociology at University of California San Francisco, and now I'm looking for a new job. If you're doing more than just study sociology, get me ready to apply here! (If not, I'll do my best to send you my\n",
            "----\n",
            "I study sociology at University of California, Fresno. His book is known for its long-fulfilling analysis of economics  which he argues is a valuable one. \"How can an idea have an unlimited possibility of being found?\" asks Dr. S\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "set_seed(100)\n",
        "input_text = \"I study sociology at University of California\"\n",
        "# specifying the maximum length of the output, and the number of different sequences you want\n",
        "output = generator(input_text, max_length=50, num_return_sequences=5)\n",
        "for result in output:\n",
        "    print(result['generated_text'])\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTwfoj46CP0b"
      },
      "source": [
        "# Challenge\n",
        "We can experiment changing different hyper parameters in the model above. Experiment by specifying different values for *temperature* parameter in generator function.\n",
        "<br>\n",
        "Temperature regulates the unpredictability of a language model's output. With higher temperature settings, outputs become more creative and less predictable as it amplifies the likelihood of less probable tokens while reducing that for more probable ones. A temperature value that is higher, such as 1.7, encourages the generation of text that is more varied and imaginative. Conversely, a lower temperature value, like 0.7, steers the output towards more concentrated and predictable text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uMwf8nqCP0b",
        "outputId": "46c981fd-f9c1-4b99-e792-397d66b622e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I study sociology at University of California, Berkeley, and I'm interested in what it means for people to become social scientists and also to be part of the social sciences. I'm interested in how we understand people's social roles in society and how they\n",
            "----\n",
            "I study sociology at University of California, Berkeley.\n",
            "\n",
            "The author is a member of the Board of Trustees of the University of California, Davis.\n",
            "----\n",
            "I study sociology at University of California, Oakland. I am an undergraduate in psychology at the University of California, Berkeley, and work for the Department of Social Work at the University of California, Berkeley.\n",
            "\n",
            "My undergraduate years were primarily spent studying the\n",
            "----\n",
            "I study sociology at University of California, Berkeley. I'm fascinated by the nature of social change and the ways it's brought about in our society. How does the world affect you? When does social change affect your daily life?\n",
            "\n",
            "I'm\n",
            "----\n",
            "I study sociology at University of California, Irvine. In the early 1990s, I left graduate school and began teaching sociology at the University of Illinois, Chicago. In 2001, I was hired by the University of Colorado to teach at the University of Michigan\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "output = generator(input_text, max_length=50, num_return_sequences=5, temperature = 0.7)\n",
        "for result in output:\n",
        "    print(result['generated_text'])\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWZ5GKy3CP0b"
      },
      "source": [
        "We used GPT2 to generate text above because it is free and runs relatively faster to be able to demonstrate in a classroom setting.  Sometimes, using a larger and more powerful model such as GPT-3 instead of GPT-2 can improve the quality of the generated text. Larger models often capture nuances and subtleties better. However, larger models often take longer time to run and some of the newest models are only available through a paid API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP_oJhO0WcJV"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "Let's practice with another task from [huggingface](https://huggingface.co/docs/transformers/task_summary).\n",
        "\n",
        "Let's say we want to check our data for grammatical correctness. We will use the CoLA model (\"textattack/distilbert-base-uncased-CoLA\") in the Text Classification pipeline ('text-classification') What is the grammatical correctness of each of the first 15 entries in the cfpb dataset?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cnh_0zQjfEf",
        "outputId": "8ee9a50b-a09a-4d17-ffe2-14d542335a47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_1', 'score': 0.9881684184074402}]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "#solution\n",
        "classifier = pipeline(\"text-classification\", model = \"textattack/distilbert-base-uncased-CoLA\")\n",
        "classifier(\"I went to the bus.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_pNEaqhpKHq"
      },
      "source": [
        "There are thousands of models on huggingface that can be used for a variety of language tasks. This can be a great way to use the models already available to increase our modeling power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yLbtugXYBqV"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "This lab has introduced Colab as a way to use GPUs to speed up processing power and explored further applications of deep learning to natural language processing.\n",
        "\n",
        "In practice, using deep learning for computational social science requires building on the foundational concepts covered in this notebook to implement models with more complicated data and architecture. However, there are many strategies can help you navigate the model ecosystem, some of which we will discuss here:\n",
        "\n",
        "1. Documentation (and other resources like tutorials) is a goldmine of information for implementing particular algorithms and completing specific tasks. This is one reason why reading and translating code written by others is a key skill.\n",
        "\n",
        "2. Debugging and interpreting error messages, as well as leveraging online resources in order to resolve them, is another key concept. Resources like documentation and Stack Overflow help solve common errors and get code working faster.\n",
        "\n",
        "3. Computational resources are important for running complex models. Google Colab has access to GPUs, but does have limitations for large and extended jobs. In those cases, options are paid services such as Google Colab Pro or on-campus [resources](https://docs-research-it.berkeley.edu/services/high-performance-computing/overview/).\n",
        "\n",
        "4. Further resources:\n",
        "  - Deep Learning with Python (Francois Chollet)\n",
        "  - [Huggingface course](https://huggingface.co/course/chapter1/1)\n",
        "  - [Tensorflow](https://www.tensorflow.org/tutorials)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "L_zANHRDhplZ",
        "pi2ikVCaoNct",
        "F9xyYBVVRZlE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}