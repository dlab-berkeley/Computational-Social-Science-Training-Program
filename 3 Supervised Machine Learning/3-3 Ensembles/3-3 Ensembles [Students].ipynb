{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Computational Social Science]\n",
    "## 3-3 Tree-Based Ensemble Methods - Student Version\n",
    "\n",
    "In this lab, we will explore extensions of decision trees. Particularly, we will introduce ensemble machine learning. This  which involves combining several machine learning algorithms together to create a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Virtual Environment\n",
    "Remember to always activate your virtual environment first before you install packages or run a notebook! This helps to prevent conflicts between dependencies across different projects and ensures that you are using the correct versions of packages. You must have created anaconda virtual enviornment in the `Anaconda Installation` lab. If you have not or want to create a new virtual environment, follow the instruction in the `Anaconda Installation` lab. \n",
    "\n",
    "<br>\n",
    "\n",
    "If you have already created a virtual enviornment, you can run the following command to activate it: \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda activate <virtual_env_name>`\n",
    "\n",
    "<br>\n",
    "\n",
    "For example, if your virtual environment was named as CSS, run the following command. \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda activate CSS`\n",
    "\n",
    "<br>\n",
    "\n",
    "To deactivate your virtual environment after you are done working with the lab, run the following command. \n",
    "\n",
    "<br>\n",
    "\n",
    "`conda deactivate`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We're going to use our [Census Income dataset](https://archive.ics.uci.edu/dataset/20/census+income) again for this lab. Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "#sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of column names, found in \"adult.names\"\n",
    "# ----------\n",
    "col_names = ['age', \n",
    "             'workclass', \n",
    "             'fnlwgt',\n",
    "             'education', \n",
    "             'education-num',\n",
    "             'marital-status', \n",
    "             'occupation', \n",
    "             'relationship', \n",
    "             'race', \n",
    "             'sex', \n",
    "             'capital-gain',\n",
    "             'capital-loss', \n",
    "             'hours-per-week',\n",
    "             'native-country', \n",
    "             'income-bracket']\n",
    "\n",
    "# Read table from the data folder\n",
    "census = pd.read_table(\"../../data/adult.data\", \n",
    "                       sep = ',', \n",
    "                       names = col_names)\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, we need to preprocess the data to binarize the target and dummify our categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "# ----------\n",
    "lb = LabelBinarizer()\n",
    "y = census['income-bracket-binary'] = lb.fit_transform(census[\"income-bracket\"])\n",
    "\n",
    "# Features\n",
    "# ----------\n",
    "X = census.drop(['income-bracket', 'fnlwgt', 'income-bracket-binary'], axis = 1)\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first model we will look at is the decision tree. Using the [`tree.DecisionTreeClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) method, let's implement a cross-validation approach to predicting income. We will initialize the model with the standard configurations from the Classification lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a Decision Tree Classifier\n",
    "# ----------\n",
    "dt_classifier = tree.DecisionTreeClassifier(\n",
    "                       criterion='gini',              # or 'entropy' for information gain\n",
    "                       splitter='best',               # or 'random' for random best split\n",
    "                       max_depth=None,                # set how deep tree nodes can go\n",
    "                       min_samples_split=2,           # samples needed to split node\n",
    "                       min_samples_leaf=1,            # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,  # weight of samples needed for a node\n",
    "                       max_features=None,             # number of features to look for when splitting\n",
    "                       max_leaf_nodes=None,           # max nodes\n",
    "                       min_impurity_decrease=1e-07,   # early stopping\n",
    "                       random_state = 10)             #random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score returns the accuracy score by default but you can change this with the \"scoring\" argument\n",
    "scores = cross_val_score(dt_classifier,   # specify estimator \n",
    "                         X,               # specify X\n",
    "                         y,               # specify y\n",
    "                         cv=5)            # number of cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the scores individually\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the mean score from the results of cross validation\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".82 accuracy, not bad! We can also visualize the decision tree to see how it made its splits. Note we limit the max depth to 4 so that the code runs quickly, but in practice you might want to visualize the entire tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the length of our feature dataframe to be able to judge splits by # of observations\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to data\n",
    "# ----------\n",
    "dt_classifier.fit(X, y)\n",
    "\n",
    "# set column names as list\n",
    "# ----------\n",
    "column_names = X.columns.tolist()\n",
    "\n",
    "# plot the figure\n",
    "# ----------\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "_ = tree.plot_tree(dt_classifier, \n",
    "                   feature_names=column_names,      # make sure its a list\n",
    "                   class_names=[\"<=50k\", \">50k\"],   # specify class names\n",
    "                   filled=True,                     # paint nodes to indicate majority class \n",
    "                   fontsize = 15,                   # set fontsize\n",
    "                   max_depth = 3)                   # set max depth of tree to view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the .max_depth attribute to check out the depth of our entire tree\n",
    "# ----------\n",
    "dt_classifier.tree_.max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind ourselves how many samples in our negative class\n",
    "# ----------\n",
    "np.count_nonzero(y==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the samples after root node\n",
    "# ----------\n",
    "X['marital-status_ Married-civ-spouse'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the most informative features\n",
    "# ----------\n",
    "importances = pd.DataFrame({'feature':X.columns,'importance':np.round(dt_classifier.feature_importances_,3)})\n",
    "importances = importances.sort_values('importance',\n",
    "                                      ascending=False)\n",
    "importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning\n",
    "Ensemble learning is a machine learning paradigm where multiple learners (also known as base or individual models) are trained to solve the same problem. The main idea behind ensemble learning is that a group of \"weak learners\" can come together to form a \"strong learner\". Each weak learner makes a prediction, and then the ensemble model makes its final prediction based on the votes or the outputs of all the weak learners.\n",
    "\n",
    "Ensemble learning often significantly improves machine learning results by combining several models. This approach allows the production of better predictive performance compared to a single model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Next, we'll take a look at the [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). Random Forest is an extension of the decision tree method. Rather than construct just one tree, a random forest grows many trees, using a subset of features to grow each tree. The trees then make predictions, and the random forest takes a majority vote from the trees to determine the winner. Random forest is known as a [\"bagging\"](https://en.wikipedia.org/wiki/Bootstrap_aggregating) method. Fill in the code below to train a random forest using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a random forest classifier\n",
    "# ----------\n",
    "rf_classifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify cross-validation\n",
    "# ----------\n",
    "scores = cross_val_score(..., \n",
    "                         ..., \n",
    "                         ...,  # Some algorithms will expect you to ravel the target\n",
    "                         ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the average score across models\n",
    "# ----------\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it is difficult to visualize a forest of trees, we *can* still visualize the feature importances. Use the code below to look at the top 10 most important features. \n",
    "\n",
    "**QUESTION:** What do you notice? Do you think we actually need a large feature space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the random forest on data to get feature importance\n",
    "# ----------\n",
    "rf_classifier.fit(X, y.ravel())\n",
    "\n",
    "# import library\n",
    "import seaborn as sns\n",
    "\n",
    "# create feature importance dataframe\n",
    "feat_importances = pd.concat([pd.DataFrame(X.columns),pd.DataFrame(np.transpose(rf_classifier.feature_importances_))], axis = 1)\n",
    "feat_importances.columns = [\"Feature\", \"Importance\"]\n",
    "\n",
    "# plot\n",
    "sns.barplot(x = \"Importance\", \n",
    "            y = \"Feature\",  \n",
    "            data = feat_importances.nlargest(10, 'Importance')) # identify the 10 most important features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** Prob not, since it seems that only a handful of predictors are making important contributions to splitting the data (reducing impurity). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that only a handful of features are contributing a lot to the model. We could probably simplify the decisionmaking considerably. Try training a new decision tree with max depth 5 and only use the 10 most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit a basic decision tree using reduced number of features \n",
    "# ----------\n",
    "dt_reduced_classifier = ...\n",
    "\n",
    "# pull out the most features\n",
    "important_features = feat_importances.nlargest(10, 'Importance')['Feature']\n",
    "\n",
    "# create new dataset with only most important features\n",
    "X_reduced = X[X.columns[X.columns.isin(important_features)]]\n",
    "\n",
    "# fit the model on the new reduced model\n",
    "dt_reduced_classifier.fit(..., \n",
    "                          ...)\n",
    "\n",
    "# fit the model on the new reduced model\n",
    "dt_reduced_classifier.fit(X_reduced,\n",
    "                          y)\n",
    "# set column names as list\n",
    "reduced_column_names = X_reduced.columns.tolist()\n",
    "fig = plt.figure(figsize=(45,40))\n",
    "_ = tree.plot_tree(decision_tree = ...\n",
    "                   feature_names=reduced_column_names,  # make sure its a list\n",
    "                   class_names=...,                     # specify class names\n",
    "                   filled=...,                          # paint nodes to indicate majority class \n",
    "                   fontsize = 25,                       # set fontsize\n",
    "                   max_depth = 3)                       # set max depth of tree to view      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks a lot more interpretable than a random forest! How did we do on accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using cross validation\n",
    "# ----------\n",
    "scores = cross_val_score(..., \n",
    "                         ..., \n",
    "                         ..., \n",
    "                         ...)\n",
    "\n",
    "# find the mean score across models\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost .85! Slightly better then the whole random forest and better than our original decision tree. Growing a random forest and then simplifying down to a more basic decision tree is the basic procedure recommended by the [select-regress-round](https://arxiv.org/pdf/1702.04690.pdf) framework.\n",
    "\n",
    "**Question**: Why did a simplified decision tree get better accuracy than the first one we ran?\n",
    "\n",
    "**Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other approach for ensembling decision trees is called [\"boosting\"](https://en.wikipedia.org/wiki/Boosting_(machine_learning). Whereas random forests grow many decision trees in parallel and take a vote from them, boosting algorithms start with a strong classifier and iterate on it with weak learners. The weak learners are trained on the errors, which makes boosting algorithms well suited for making classifications in difficult cases. Try filling in the code below to train an [`AdaBoostClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a Adaptive boosting classifer \n",
    "# ----------\n",
    "ada_classifier = ...   # specify 100 estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using cross validation\n",
    "# ----------\n",
    "scores = ...          # specify 5-fold cross-validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** How does adaptive boosting compare the the random forest, the reduced feature tree, and the basic tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy using cross validation\n",
    "# ----------\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** What are some pros and cons of adaptive boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a [link to a tutorial](https://medium.com/@chaudhurysrijani/tuning-of-adaboost-with-computational-complexity-8727d01a9d20) on `AdaBoost()` that uses a data visualization workflow (box-plots) to visually compare model accuracy of different hyperparameters. This particular workflow relies on user-written functions to create the dataframes necessary for visualization. \n",
    "\n",
    "So, while it is not is not as code-efficient as using GridSearchCV(), it could be helpful in understand model accuracy differences across a particualr hyperparameter and could be a workflow you might want to use to illustrate a point in a paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[XGBoost](https://xgboost.readthedocs.io/en/stable/) also uses sequential weak learners to train the models instead of creating a random forest. \n",
    "\n",
    "One key difference from `AdaBoost()` is that it uses Gradient Descent to minimize a loss function and improve fit whereas `AdaBoost()` assigns larger weights to incorrectly classified observations so that future models focus on classifying those observations in future models. \n",
    "\n",
    "Here is a [helpful explainer](https://medium.com/@thedatabeast/adaboost-gradient-boosting-xg-boost-similarities-differences-516874d644c6#:~:text=AdaBoost%20is%20generally%20slower%20than,explicit%20imputation%20of%20missing%20values.) the similarities and differences between these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will likely have to install xgboost using the command-line prompt below\n",
    "# !pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize an XGBoost classifer \n",
    "# ----------\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=..)\n",
    "\n",
    "\n",
    "# define the scoring metrics\n",
    "scoring = {\n",
    "          'accuracy': make_scorer(..),\n",
    "          'recall': make_scorer(..),\n",
    "          'precision': make_scorer(..),\n",
    "          'f1': make_scorer(..)\n",
    "           }\n",
    "\n",
    "# perform cross-validation with 5-fold and return the trained estimators\n",
    "cv_results = cross_validate(...,                   # specify estimator \n",
    "                            X,                     # specify features\n",
    "                            y.ravel(),             # specify outcome, and use ravel\n",
    "                            cv=...,                # specify 5-fold cross validation\n",
    "                            return_estimator=True, # return the estimators fitted at each split\n",
    "                            scoring=...)           # which scoring metrics to return (the whole list in this case)\n",
    " \n",
    "\n",
    "# print the results for accuracy, recall, precision, and F1 score\n",
    "for metric in ['test_accuracy', 'test_recall', 'test_precision', 'test_f1']:\n",
    "    scores = cv_results[metric]\n",
    "    print(f\"{metric[5:]}: {scores.mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the feature importance\n",
    "# ----------\n",
    "\n",
    "# Initialize an array to hold the feature importances\n",
    "importances = np.zeros(X.shape[1])\n",
    "\n",
    "# Average the feature importances over the folds\n",
    "for estimator in cv_results['estimator']:\n",
    "    importances += estimator.feature_importances_\n",
    "    \n",
    "# Divide by the number of folds\n",
    "importances /= ...  \n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance = pd.DataFrame({'feature': X.columns, \n",
    "                                   'importance': importances})\n",
    "\n",
    "# Sort the features by importance\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Take the top 10 features\n",
    "feature_importance = feature_importance.head(10)\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# horizontal bar plot\n",
    "plt.barh(feature_importance['feature'], \n",
    "         feature_importance['importance'], \n",
    "         color='maroon', \n",
    "         align='center')\n",
    "\n",
    "# labels\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Feature Importance')\n",
    "\n",
    "# gca stands for \"get current axis\", which allows you to modify the properties of the axes.\n",
    "# and then inverts the y-axis, meaning that the values that were at the bottom will now be at the top, and vice versa.\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Learning Beyond Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also create ensembles with algorithms beyond decision trees. Scikit's ensemble module contains several different options for training ensemble models. Here, we will focus on the [`VotingClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) method. A voting classifier works in a similar fashion to random forest. However, **instead of taking a majority vote of decision trees, it takes a majority vote of various algorithms.** \n",
    "\n",
    "The voting can be **\"hard\"** which means the ensemble uses a majority vote of predicted classes, or **\"soft\"** meaning the votes are weighted by the probability associated with the prediction. \n",
    "\n",
    "Run the code below to initialize a logistic regression, a random forest, and an adaboost model. Pass all three of these into the VotingClassifier to train an ensemble model, and check out their accuracy scores.\n",
    "\n",
    "*Note that this may take a minute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression using liblinear solver\n",
    "# ----------\n",
    "log_reg = LogisticRegression(random_state = 10, \n",
    "                             solver='liblinear')\n",
    "\n",
    "# Random Forest\n",
    "# ----------\n",
    "rf_classifier = RandomForestClassifier(\n",
    "                       criterion='gini',                  # or 'entropy' for information gain\n",
    "                       max_depth=None,                    # how deep tree nodes can go\n",
    "                       min_samples_split=2,               # samples needed to split node\n",
    "                       min_samples_leaf=1,                # samples needed for a leaf\n",
    "                       min_weight_fraction_leaf=0.0,      # weight of samples needed for a node\n",
    "                       max_features=None,                 # number of features to look for when splitting\n",
    "                       max_leaf_nodes=None,               # max nodes\n",
    "                       min_impurity_decrease=1e-07,       # early stopping\n",
    "                       random_state = 10)                 # random seed\n",
    "\n",
    "# AdaBoost\n",
    "# ----------\n",
    "ada_classifier = AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "# XGBoost\n",
    "# ----------\n",
    "xgb_classifier = xgb.XGBClassifier(random_state=10)\n",
    "\n",
    "# specify voting classifiers\n",
    "# ----------\n",
    "voting_classifier = VotingClassifier(\n",
    "                        # specify estimators to use\n",
    "                        estimators = [('lr', log_reg),\n",
    "                                     ('rf', rf_classifier),\n",
    "                                     ('ada', ada_classifier)],\n",
    "                        # specify voting\n",
    "                        voting = 'hard')\n",
    "\n",
    "# loop through each model to report accuracy\n",
    "# ----------\n",
    "for clf, label in zip([log_reg, \n",
    "                       rf_classifier, \n",
    "                       ada_classifier, \n",
    "                       xgb_classifier,\n",
    "                       voting_classifier], ['Logistic Regression', \n",
    "                                            'Random Forest', \n",
    "                                            'Ada Boost',\n",
    "                                            'XGBoost',\n",
    "                                            'Ensemble']):\n",
    "         scores = cross_val_score(clf, \n",
    "                                  X, \n",
    "                                  y.ravel(), \n",
    "                                  scoring='accuracy', \n",
    "                                  cv=5)\n",
    "         print('Accuracy: %0.2f [%s]' % (scores.mean(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION:** How did the ensemble do? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:** ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try to use a soft voting classifier to get the predicted probabilities for each prediction. Try using the `predict_proba()` method to get the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify a \"soft\" voting classifer in this iteration\n",
    "# ----------\n",
    "voting_classifier = VotingClassifier(\n",
    "                        # specify estimators to use\n",
    "                        estimators = [('lr', log_reg),\n",
    "                                     ('rf', rf_classifier),\n",
    "                                     ('ada', ada_classifier), \n",
    "                                     ('xgb', xgb_classifier)],\n",
    "                        # specify voting \n",
    "                        voting = 'soft')\n",
    "\n",
    "# fit each classifer \"c\" to the data, predict the probability of tha clasifer and store as \"probas\"\n",
    "probas = [c.fit(X, y.ravel()).predict_proba(X)[:,1] for c in (log_reg, \n",
    "                                                              rf_classifier,\n",
    "                                                              ada_classifier,\n",
    "                                                              xgb_classifier,\n",
    "                                                              voting_classifier)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our predicted probabilities into a dataframe so we can visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset from the predicted probabilities\n",
    "# ----------\n",
    "probs_df = pd.DataFrame.from_records(probas).T # pulls the list of \"probas\" and stores as dataframe\n",
    "probs_df.rename(columns = {0: 'logit',\n",
    "                           1: 'rf',\n",
    "                           2: 'ada',\n",
    "                           3: 'xgb',\n",
    "                           4: 'ensemble'}, \n",
    "                inplace = True)\n",
    "\n",
    "# view the first few observations\n",
    "# ----------\n",
    "probs_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize distributions\n",
    "# ----------\n",
    "# set figure parameters\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# logit\n",
    "ax = fig.add_subplot(2, 3, 1)\n",
    "sns.histplot(probs_df, x=\"logit\", ax=ax)\n",
    "\n",
    "# random forest\n",
    "ax = fig.add_subplot(2, 3, 2)\n",
    "sns.histplot(probs_df, x=\"rf\", ax=ax)\n",
    "\n",
    "# adaptive boosting\n",
    "ax = fig.add_subplot(2, 3, 3)\n",
    "sns.histplot(probs_df, x=\"ada\", ax=ax)\n",
    "\n",
    "# xgboost\n",
    "ax = fig.add_subplot(2, 3, 4)\n",
    "sns.histplot(probs_df, x=\"xgb\", ax=ax)\n",
    "\n",
    "# ensemble\n",
    "ax = fig.add_subplot(2, 3, 5)\n",
    "sns.histplot(probs_df, x=\"ensemble\", ax=ax)\n",
    "\n",
    "# show plot \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**QUESTION**: Do you notice something about the distribution of the predicted probabilities? Can you explain the output of `AdaboostClassifier`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Authored by Aniket Kesari. Minor edits by Tom van Nuenen 2022. Notation and note about XGBoost added by Kasey Zapatka in Fall 2023."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
