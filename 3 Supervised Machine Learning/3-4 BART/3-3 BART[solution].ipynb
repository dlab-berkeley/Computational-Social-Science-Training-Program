{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15ff7bd",
   "metadata": {},
   "source": [
    "# BART\n",
    "\n",
    "In this lab, we will cover BART. Bayesian Additive Regression Trees (BART) is a non-linear, non-parametric Bayesian statistical model. It's used for regression and classification problems and has been shown to provide flexible fits to complex datasets, often outperforming traditional methods like linear regression or classification and regression trees.\n",
    "\n",
    "BART models data as a sum of decision trees where each tree is constrained by a prior to be a weak learner, contributing a small amount to the overall prediction. This setup helps in avoiding overfitting, which is a common problem with methods that use decision trees, such as random forests.\n",
    "\n",
    "In more technical terms, given a response variable Y and predictor variables X1, X2, ..., Xp, BART assumes the following relationship:\n",
    "\n",
    "Y = f(X1, X2, ..., Xp) + e\n",
    "\n",
    "where f(X1, X2, ..., Xp) is an unknown function and e is a normally distributed error term. BART approximates the unknown function f by an additive model of binary trees.\n",
    "\n",
    "The \"Bayesian\" part of BART comes in because it uses Bayesian methods to learn from the data and make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8736cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pymc\n",
    "#!pip3 install pymc_bart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50e91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f6d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az #ArviZ is a Python package for exploratory analysis of Bayesian models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm #PyMC (formerly PyMC3) is a Python package for Bayesian statistical modeling\n",
    "import pymc_bart as pmb # PyMC-BART extends PyMC \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\") #bart might not work in older version of pymc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefff6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 300\n",
    "np.random.seed(RANDOM_SEED)\n",
    "az.style.use(\"arviz-darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89c93fb",
   "metadata": {},
   "source": [
    "In this lab, we will first use coal mining disaster dataset. This is a popular dataset in the PYMC library documentation. We will discretize the dataset by building a histogram and use center of bins as x variable and counts per bin as y variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ec02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file \"coal.csv\" would be included in the PyMC library installation on your computer\n",
    "# As per the numpy.loadtxt() function, it expects the file to be a text file with numerical\n",
    "# data, and it will load this data into a NumPy array called coal. csv file is a type of text file.\n",
    "coal = np.loadtxt(pm.get_data(\"coal.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddd3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize data\n",
    "years = int(coal.max() - coal.min()) # calculates the range of the data. If the coal \n",
    "# dataset represents years, this would give the number of years the data spans.\n",
    "bins = years // 4 # '//' calculates the number of bins for the histogram by \n",
    "# performing floor division. The // operator divides and rounds down to the nearest whole \n",
    "# number. \n",
    "hist, x_edges = np.histogram(coal, bins=bins) # hist will be an array with the number of\n",
    "# elements in each bin, and x_edges will be an array with the edge values of the bins.\n",
    "# compute the location of the centers of the discretized data\n",
    "\n",
    "x_centers = x_edges[:-1] + (x_edges[1] - x_edges[0]) / 2 #  calculates the centers of the\n",
    "# bins. It does this by adding half the bin width ((x_edges[1] - x_edges[0]) / 2) \n",
    "# to the left edges of the bins (x_edges[:-1]). This is done to represent each bin by\n",
    "#its center point rather than its edges.\n",
    "\n",
    "x_data = x_centers[:, None] # converts x_centers into a 2D array with one column. \n",
    "# The None indexing is used to add an extra dimension. This is done because the BART  \n",
    "# model expects 2D input.\n",
    "\n",
    "# just renames hist to y_data. This data represents the counts in each bin \n",
    "# (or the number of disasters per year).\n",
    "y_data = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_coal: # This line is creating a new probabilistic model using PyMC3. Everything that happens within the with block pertains to this model_coal.\n",
    "    μ_ = pmb.BART(\"μ_\", X=x_data, Y=np.log(y_data), m=20) # This line is defining a BART model with the predictor variable X set to x_data and the response variable Y set to np.log(y_data). The m=20 parameter is defining the number of trees to use in the BART model. The output of this model is being stored in μ_\n",
    "\n",
    "    \n",
    "    μ = pm.Deterministic(\"μ\", pm.math.exp(μ_)) # This line is defining a deterministic variable μ, which is the exponential of μ_. This is done because μ_ is on the log scale due to the np.log(y_data) used in the BART model.\n",
    "    y_pred = pm.Poisson(\"y_pred\", mu=μ, observed=y_data)\n",
    "    idata_coal = pm.sample(random_seed=RANDOM_SEED)# sample from the posterior distribution of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a254e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(10, 6)) # The underscore (_) is a common convention in Python for a variable name that we don't plan to use.\n",
    "\n",
    "rates = idata_coal.posterior[\"μ\"] / 4\n",
    "rate_mean = rates.mean(dim=[\"draw\", \"chain\"])\n",
    "ax.plot(x_centers, rate_mean, \"w\", lw=3)\n",
    "ax.plot(x_centers, y_data / 4, \"k.\")\n",
    "az.plot_hdi(x_centers, rates, smooth=False)\n",
    "az.plot_hdi(x_centers, rates, hdi_prob=0.5, smooth=False, plot_kwargs={\"alpha\": 0})\n",
    "ax.plot(coal, np.zeros_like(coal) - 0.5, \"k|\")\n",
    "ax.set_xlabel(\"years\")\n",
    "ax.set_ylabel(\"rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1baa52ec",
   "metadata": {},
   "source": [
    "The white line in the plot above shows the median rate of accidents. The darker orange band represent the HDI 50% and the lighter one the 94%. We can see a rapid decrease of coal accidents between 1880 and 1900. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abedf00",
   "metadata": {},
   "source": [
    "\n",
    "The following figure shows two samples of μ\n",
    "from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.step(x_data, rates.sel(chain=0, draw=[3, 10]).T);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ad765a",
   "metadata": {},
   "source": [
    "Now let's explore BART using four covariate using a subset of popular bike sharing dataset.\n",
    "We will use the following variables: number of bike rental in a city, the hour of the day, the temperature, the humidity, and whether it is a weekday or weekend. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956070a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = pd.read_csv(pm.get_data(\"bikes.csv\"))  # the file bikes.csv is included in pymc installation\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8518fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"hour\", \"temperature\", \"humidity\", \"workingday\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdaecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bikes[features]\n",
    "Y = bikes[\"count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ac1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as model_bikes:\n",
    "    α = pm.Exponential(\"α\", 1)\n",
    "    μ = pmb.BART(\"μ\", X, np.log(Y), m=50)\n",
    "    y = pm.NegativeBinomial(\"y\", mu=pm.math.exp(μ), alpha=α, observed=Y)\n",
    "    idata_bikes = pm.sample(compute_convergence_checks=False, random_seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118f04ed",
   "metadata": {},
   "source": [
    "# Partial dependence plots\n",
    "\n",
    "To aid in the interpretation of our model's results, we will employ partial dependence plots. These plots demonstrate the marginal effect of one covariate on the predicted variable. PyMC-BART provides an utility function to make this plot from the inference data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e7c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmb.plot_pdp(μ, X=X, Y=Y, grid=(2, 2), func=np.exp) # explore plot_pdp function futher at https://github.com/pymc-devs/pymc-bart/blob/main/pymc_bart/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54913372",
   "metadata": {},
   "source": [
    "From the plot above, we can see the main effect of each covariate on the predicted value. For example for the hour covariate we can see two peaks around 8 and and 17 hs and a minimum at 12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e29f112",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "The lab was adapted from the following official documentation in PyMC. https://www.pymc.io/projects/examples/en/latest/case_studies/BART_introduction.html Please explore the official documentation if you want to learn more. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72f38f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
